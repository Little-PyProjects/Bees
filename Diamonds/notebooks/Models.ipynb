{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20085915",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d20816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This isn't strictly needed. However it solves this annoying pandas error:\n",
    "\n",
    "/opt/homebrew/Caskroom/miniforge/base/envs/supervised/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
    "  from pandas import MultiIndex, Int64Index\n",
    "  \n",
    "The problem is solved with xgboost 1.6 but I don't want to use pip in this case and the conda package is currently 1.5.1  \n",
    "'''\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82e567b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6576a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/diamonds.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51302542",
   "metadata": {},
   "source": [
    "### Preparing the model -- 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "744d80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = df.select_dtypes(exclude=np.number).columns.to_list()\n",
    "#categoricals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df72444",
   "metadata": {},
   "source": [
    "#### Is it faster to use the pandas `get_dummies` or scikit's `label_encoder`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6626c44",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    \n",
    "```\n",
    "%timeit pd.get_dummies(df,df.columns[df.dtypes == 'object'])\n",
    "\n",
    "212 ms ± 2.51 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "```\n",
    "vs\n",
    "```\n",
    "%timeit label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "for col in categoricals:\n",
    "    df[(col)]=label_encoder.fit_transform(df[(col)])\n",
    "    \n",
    "71.8 ns ± 0.0599 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n",
    "```\n",
    "#### Pandas takes about 3 million times as long to do the operation. Wow! That's a _huge_ difference! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0d2684d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shape</th>\n",
       "      <th>size</th>\n",
       "      <th>color</th>\n",
       "      <th>fancy_color_dominant_color</th>\n",
       "      <th>fancy_color_secondary_color</th>\n",
       "      <th>fancy_color_overtone</th>\n",
       "      <th>fancy_color_intensity</th>\n",
       "      <th>clarity</th>\n",
       "      <th>cut</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>...</th>\n",
       "      <th>meas_depth</th>\n",
       "      <th>girdle_min</th>\n",
       "      <th>girdle_max</th>\n",
       "      <th>culet_size</th>\n",
       "      <th>culet_condition</th>\n",
       "      <th>fluor_color</th>\n",
       "      <th>fluor_intensity</th>\n",
       "      <th>lab</th>\n",
       "      <th>total_sales_price</th>\n",
       "      <th>eye_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.77</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   shape  size  color  fancy_color_dominant_color  \\\n",
       "0     10  0.09      1                          12   \n",
       "1     10  0.09      1                          12   \n",
       "2     10  0.09      1                          12   \n",
       "3     10  0.09      1                          12   \n",
       "\n",
       "   fancy_color_secondary_color  fancy_color_overtone  fancy_color_intensity  \\\n",
       "0                           10                     8                      9   \n",
       "1                           10                     8                      9   \n",
       "2                           10                     8                      9   \n",
       "3                           10                     8                      9   \n",
       "\n",
       "   clarity  cut  symmetry  ...  meas_depth  girdle_min  girdle_max  \\\n",
       "0       10    0         4  ...        1.79           0           0   \n",
       "1       10    5         4  ...        1.78           1           1   \n",
       "2       10    0         4  ...        1.77           4           0   \n",
       "3       10    0         4  ...        1.78           0           1   \n",
       "\n",
       "   culet_size  culet_condition  fluor_color  fluor_intensity  lab  \\\n",
       "0           3                3            5                2    2   \n",
       "1           3                3            5                2    2   \n",
       "2           8                3            5                2    2   \n",
       "3           8                3            5                2    2   \n",
       "\n",
       "   total_sales_price  eye_clean  \n",
       "0                200          4  \n",
       "1                200          4  \n",
       "2                200          4  \n",
       "3                200          4  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "for col in categoricals:\n",
    "    df[(col)]=label_encoder.fit_transform(df[(col)])\n",
    "\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d86fb8d",
   "metadata": {},
   "source": [
    "### Preparing the model -- 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81fe17e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['total_sales_price'],axis=1)\n",
    "y = df['total_sales_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bc90343",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=314)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc29eca",
   "metadata": {},
   "source": [
    "## Linear Regression for a baseline\n",
    "```\n",
    "72.4 ms ± 5.24 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "\n",
    "RMSE: 16057.10618458078\n",
    "R2  : 0.7728174575988863\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6741881e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 16057.10618458078\n",
      "R2  : 0.7728174575988863\n"
     ]
    }
   ],
   "source": [
    "lin_reg_model = LinearRegression()\n",
    "model = lin_reg_model.fit(X_train, y_train)\n",
    "y_hat= model.predict(X_test)\n",
    "\n",
    "print(\"RMSE: {}\".format(np.sqrt(mean_squared_error((y_test),(y_hat)))))\n",
    "print(\"R2  : {}\".format(np.sqrt(r2_score((y_test),(y_hat)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee47597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave this commented unless you have a few extra minutes to spare\n",
    "\n",
    "# rr  = RandomForestRegressor()\n",
    "# rr.fit(X_train,y_train)\n",
    "# y_pred = rr.predict(X_test)\n",
    "\n",
    "# print(\"RMSE: {}\".format(np.sqrt(mean_squared_error((y_test),(y_pred)))))\n",
    "# print(\"R2  : {}\".format(np.sqrt(r2_score((y_test),(y_pred)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "561ae052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Regression has a 40.6 % improvement over baseline in RMSE \n",
      "and a 19.9 % improvement in R2\n",
      "      \n",
      "... but takes about 1,000x longer to run.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Random Forest Regression has a {round((16057.1061-9536.7866)/16057.1061 *100 , 1)} % improvement over baseline in RMSE \n",
    "and a {round((.9262440179416279-.7728174575988863)/.7728174575988863 *100 , 1)} % improvement in R2\n",
    "      \n",
    "... but takes about 1,000x longer to run.\"\"\")\n",
    "\n",
    "# Check these numbers because it's 3AM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe7346",
   "metadata": {},
   "source": [
    "### Decision Trees - marginally better than LR. Fast but max out at depth of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f05dfd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 13921.257325084407\n",
      "R2  : 0.8350244922620658\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "tree=DecisionTreeRegressor(max_depth=3)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "print(\"RMSE: {}\".format(np.sqrt(mean_squared_error((y_test),(y_pred)))))\n",
    "print(\"R2  : {}\".format(np.sqrt(r2_score((y_test),(y_pred)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea1edf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Trees has a 13.3 % improvement over baseline in RMSE \n",
      "and a 10.9 % improvement in R2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Decision Trees has a {round((16057.1061-13921.2573)/16057.1061 *100 , 1)} % improvement over baseline in RMSE \n",
    "and a {round((.9262440179416279-.8350244922620658)/.8350244922620658 *100 , 1)} % improvement in R2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffe01b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a24c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_r = xgb.XGBRegressor(objective ='reg:squarederror', n_estimators = 1000, seed = 123, verbosity=1)\n",
    "xgb_r.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_r.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57ede615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 9079.8899616356\n",
      "R2  : 0.9333889379986995\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: {}\".format(np.sqrt(mean_squared_error((y_test),(y_pred)))))\n",
    "print(\"R2  : {}\".format(np.sqrt(r2_score((y_test),(y_pred)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2f7cb6",
   "metadata": {},
   "source": [
    "### XGBoost regression is strong for two reasons. Good performance and so much faster than Random Forrest Regression. And this is for a basically untuned model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc020fe",
   "metadata": {},
   "source": [
    "Grid Search didn't preform as well as expected. In fact it was substantially worse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759ecfed",
   "metadata": {},
   "source": [
    "Yeah, I don't get that.\n",
    "```\n",
    "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
    "Best parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 1000}\n",
    "Lowest RMSE:  25154.080799724477\n",
    "```\n",
    "\n",
    "Let's try a different set of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b369f32b",
   "metadata": {},
   "source": [
    "Started at 5:30pm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2cf9fd",
   "metadata": {},
   "source": [
    "```\n",
    "params = {'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "          'n_estimators': [50, 100, 150, 200, 300],\n",
    "          'colsample_bytree': [.5,  0.7, 0.8] }\n",
    "\n",
    "clf = GridSearchCV(estimator=xgb_r, param_grid=params,\n",
    "                   scoring='neg_mean_squared_error', verbose=1)\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))\n",
    "```\n",
    "\n",
    "Fitting 5 folds for each of 90 candidates, totalling 450 fits <br>\n",
    "Best parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.6, 'n_estimators': 300} <br>\n",
    "Lowest RMSE:  25282.458416182304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d914d60f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
